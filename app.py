import gradio as gr
import os
import requests

HF_API_URL = os.getenv("HF_API_URL", "https://api-inference.huggingface.co/models/elyza/ELYZA-japanese-Llama-2-7b-fast-instruct")
HF_API_TOKEN = os.getenv("HF_API_TOKEN", "")

BACKUP_MODELS = [
    "https://api-inference.huggingface.co/models/elyza/ELYZA-japanese-Llama-2-7b-instruct",
    "https://api-inference.huggingface.co/models/cyberagent/calm2-7b-chat",
    "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2",
    "https://api-inference.huggingface.co/models/google/flan-t5-large",
]

SYSTEM_PROMPT = """ã‚ãªãŸã¯è¾²æ¥­æ¨é€²äº‹æ¥­è€…ã§ã™ã€‚è¾²å®¶ã•ã‚“ã®è³ªå•ã‚„æ‡¸å¿µã«å¯¾ã—ã¦ã€å…±æ„Ÿçš„ã§å…·ä½“çš„ãªå›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚

å›ç­”ã®ã‚¹ã‚¿ã‚¤ãƒ«ï¼š
- è¦ªã—ã¿ã‚„ã™ã„å£èªä½“ã‚’ä½¿ã†ï¼ˆã€ŒãŠã˜ã•ã‚“ã€ã€Œä¿ºã€ã€Œã ã‚ˆã­ã€ãªã©ï¼‰
- è¾²å®¶ã•ã‚“ã®æ°—æŒã¡ã«å…±æ„Ÿã™ã‚‹ï¼ˆã€Œãã†ã ã‚ˆã­ã€ã€Œå¿ƒé…ã ã‚ˆã­ã€ã€Œåˆ†ã‹ã‚‹åˆ†ã‹ã‚‹ã€ãªã©ï¼‰
- å…·ä½“çš„ãªä¾‹ã‚„å®Ÿéš›ã®çµŒé¨“ã‚’æŒ™ã’ã‚‹ï¼ˆã€Œå»å¹´å‚åŠ ã—ãŸâ—‹â—‹ã•ã‚“ã€ã€Œå®Ÿéš›ã«ã‚„ã£ã¦ã¿ã‚‹ã¨ã€ãªã©ï¼‰
- æŠ€è¡“çš„ãªå°‚é–€ç”¨èªã‚„çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã¯é¿ã‘ã‚‹
- æŸ”è»Ÿãªè§£æ±ºç­–ã‚’ææ¡ˆã™ã‚‹
- æ—¥å¸¸çš„ãªè¨€è‘‰ã‚„æ¯”å–©ã‚’ä½¿ã†
- è¾²å®¶ã•ã‚“ã‚’å°Šé‡ã—ã€å¼·åˆ¶ã—ãªã„å§¿å‹¢ã‚’ç¤ºã™
- å®Ÿè·µçš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„èª¬æ˜ã‚’ã™ã‚‹

ä»¥ä¸‹ã®ã‚ˆã†ãªè¡¨ç¾ã‚’é¿ã‘ã‚‹ï¼š
- ã€Œçµ±è¨ˆçš„ã«è¦‹ã¦ã€ã€Œãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚Œã°ã€ã€Œç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ãã€ãªã©ã®å°‚é–€çš„è¡¨ç¾
- ã€Œæ¨å¥¨ã„ãŸã—ã¾ã™ã€ã€Œå¿…è¦ã¨ãªã‚Šã¾ã™ã€ãªã©ã®ç¡¬ã„æ•¬èª
- æ•°å€¤ã‚„ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’å¤šç”¨ã™ã‚‹èª¬æ˜

ä»£ã‚ã‚Šã«ã€ä»¥ä¸‹ã®ã‚ˆã†ãªè¡¨ç¾ã‚’ä½¿ã†ï¼š
- ã€Œå®Ÿéš›ã«ã‚„ã£ã¦ã¿ã‚‹ã¨ã€ã€Œå»å¹´ã®ãƒ‡ãƒ¼ã‚¿è¦‹ã¦ã‚‚ã€
- ã€Œä¸€ç·’ã«ã‚„ã£ã¦ã¿ã‚ˆã†ã‚ˆã€ã€Œç›¸è«‡ã—ã‚ˆã†ã­ã€
- ã€Œå¤§ä¸ˆå¤«ã ã‚ˆã€ã€Œå®‰å¿ƒã—ã¦ã€ãªã©ã®å®‰å¿ƒæ„Ÿã‚’ä¸ãˆã‚‹è¨€è‘‰"""

def generate_fallback_response(message):
    message_lower = message.lower()
    
    if "ãƒªã‚¹ã‚¯" in message or "å¿ƒé…" in message or "ä¸å®‰" in message:
        return "ãã†ã ã‚ˆã­ã€ãã®å¿ƒé…ã¯ã‚ˆãåˆ†ã‹ã‚‹ã‚ˆã€‚å®Ÿéš›ã«ã‚„ã£ã¦ã¿ã‚‹ã¨ã€æœ€åˆã¯ä¸å®‰ã‹ã‚‚ã—ã‚Œãªã„ã‘ã©ã€æ®µéšçš„ã«é€²ã‚ã¦ã„ã‘ã°å¤§ä¸ˆå¤«ã ã¨æ€ã†ã‚“ã ã€‚ä¾‹ãˆã°ã€ä¸€éƒ¨ã®ç”°ã‚“ã¼ã§ã¾ãšè©¦ã—ã¦ã¿ã¦ã€åŠ¹æœã‚’è‡ªåˆ†ã®ç›®ã§ç¢ºã‹ã‚ã¦ã‹ã‚‰åºƒã’ã‚‹ã£ã¦ã„ã†æ–¹æ³•ã‚‚ã‚ã‚‹ã‚ˆã€‚ä¸€ç·’ã«ç›¸è«‡ã—ãªãŒã‚‰é€²ã‚ã¦ã„ã“ã†ã­ã€‚"
    
    elif "åé‡" in message or "æ¸›ã‚‹" in message or "å®¶æ—" in message:
        return "å®¶æ—ã®ã“ã¨è€ƒãˆãŸã‚‰ã€ãã‚Šã‚ƒå¿ƒé…ã ã‚ˆã­ã€‚ã ã‹ã‚‰ã€ã‚‚ã—åé‡ãŒæ˜ã‚‰ã‹ã«æ¸›ã£ãŸå ´åˆã¯ã€è£œå„Ÿã‚’ã™ã‚‹ã£ã¦ç´„æŸã™ã‚‹ã‚ˆã€‚å®Ÿéš›ã«ã¯ã€å»å¹´å‚åŠ ã—ãŸè¾²å®¶ã•ã‚“ã€ã¿ã‚“ãªåé‡ã¯å¤‰ã‚ã£ã¦ãªã„ã€‚ã‚€ã—ã‚å°‘ã—å¢—ãˆã¦ã‚‹ã£ã¦äººã‚‚ã„ã‚‹ã‚“ã ã€‚ä¸­å¹²ã—ã‚’å»¶ã°ã™ã¨æ ¹ãŒæ·±ãå¼µã‚‹ã‹ã‚‰ã‹ã‚‚ã­ã€‚ã§ã‚‚ã€ä¸‡ãŒä¸€ã®ãŸã‚ã«ä¿é™ºã¯ã‹ã‘ã¨ãã€‚ãŠã˜ã•ã‚“ãŒæã™ã‚‹ã“ã¨ã¯çµ¶å¯¾ã«ã•ã›ãªã„ã€‚"
    
    elif "æ°´" in message or "ç®¡ç†" in message or "å¤§å¤‰" in message:
        return "ç¢ºã‹ã«ã€æœ€åˆã¯ã€ã„ã¤ã‚‚ã¨é•ã†ã€ã£ã¦æ„Ÿã˜ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚ã§ã‚‚å®Ÿéš›ã‚„ã£ã¦ã¿ã‚‹ã¨ã€æ°´ã‚’å…¥ã‚Œã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒ2é€±é–“é…ã‚Œã‚‹ã ã‘ã§ã€ä»–ã¯ä»Šã¾ã§ã¨å…¨ãåŒã˜ãªã‚“ã ã€‚ã‚€ã—ã‚ã€ä¸­å¹²ã—æœŸé–“ãŒé•·ã„ã‹ã‚‰ã€ãã®é–“ã¯æ°´ã®å¿ƒé…ã—ãªãã¦ã„ã„ã£ã¦è¨€ã†äººã‚‚ã„ã‚‹ã‚ˆã€‚åˆå¹´åº¦ã¯ã€ä¿ºãŒé€±1ã§æ§˜å­ã‚’è¦‹ã«æ¥ã¦ã€ã€ä»Šé€±ã¯ã“ã†ã—ã‚ˆã†ã€ã£ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã™ã‚‹ã‹ã‚‰ã€ä¸€äººã§æ‚©ã¾ãªãã¦å¤§ä¸ˆå¤«ã€‚"
    
    elif "é«˜é½¢" in message or "ä½“åŠ›" in message or "è¦šãˆ" in message:
        return "ãŠã˜ã•ã‚“ã€ä½•åå¹´ã‚‚ç±³ä½œã‚Šã‚„ã£ã¦ããŸãƒ™ãƒ†ãƒ©ãƒ³ã˜ã‚ƒãªã„ã§ã™ã‹ã€‚æ–°ã—ã„ã“ã¨ã£ã¦è¨€ã£ã¦ã‚‚ã€æ°´ã‚’æŠœãã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’2é€±é–“é…ã‚‰ã›ã‚‹ã ã‘ã€‚è‚¥æ–™ã‚‚å¤‰ãˆãªã„ã€è¾²è–¬ã‚‚å¤‰ãˆãªã„ã€æ©Ÿæ¢°ã‚‚å¤‰ãˆãªã„ã€‚ä»Šã¾ã§ã®ã‚„ã‚Šæ–¹ã«ãƒ—ãƒ©ã‚¹2é€±é–“ã™ã‚‹ã ã‘ã ã‚ˆã€‚ä½“åŠ›çš„ã«ã‚‚ã€ç‰¹ã«é‡åŠ´åƒãŒå¢—ãˆã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã€‚ã‚€ã—ã‚ã€ä¸­å¹²ã—æœŸé–“ãŒé•·ã„ã‹ã‚‰ã€ãã®é–“ã¯ç”°ã‚“ã¼ã«è¡Œãå›æ•°ãŒæ¸›ã‚‹ã£ã¦è€ƒãˆã‚‹ã“ã¨ã‚‚ã§ãã‚‹ã‚ˆã€‚"
    
    elif "å“è³ª" in message or "å‘³" in message or "å£²ã‚Œ" in message:
        return "ãã†ã ã‚ˆã­ã€ã„ãã‚‰ç’°å¢ƒã«è‰¯ãã¦ã‚‚ã€ç±³ãŒå£²ã‚Œãªãã‚ƒæœ¬æœ«è»¢å€’ã ã€‚ã ã‹ã‚‰ä»Šå›ã¯ã€å“è³ªã‚’çµ¶å¯¾ã«è½ã¨ã•ãªã„ã£ã¦ã®ãŒå¤§å‰æãªã‚“ã ã€‚å®Ÿã¯æ—¢ã«å‚åŠ ã—ã¦ã‚‹è¾²å®¶ã•ã‚“ã€å»å¹´ã¨åŒã˜ç­‰ç´šã§å‡ºè·ã§ãã¦ã‚‹ã—ã€ã‚€ã—ã‚JAã‹ã‚‰ã€ç’°å¢ƒé…æ…®ç±³ã€ã£ã¦åå‰ã§å°‘ã—é«˜ãè²·ã£ã¦ã‚‚ã‚‰ãˆãŸã£ã¦è¨€ã£ã¦ãŸã€‚ãŠã˜ã•ã‚“ã‚‚ç›´è²©ã‚„ã£ã¦ã‚‹ãªã‚‰ã€ã“ã‚Œã‚’å£²ã‚Šã«ã§ãã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã‚ˆã€‚"
    
    else:
        return "ãã†ã ã‚ˆã­ã€ãã®å¿ƒé…ã¯ã‚ˆãåˆ†ã‹ã‚‹ã‚ˆã€‚å®Ÿéš›ã«ã‚„ã£ã¦ã¿ã‚‹ã¨ã€æœ€åˆã¯ä¸å®‰ã‹ã‚‚ã—ã‚Œãªã„ã‘ã©ã€æ®µéšçš„ã«é€²ã‚ã¦ã„ã‘ã°å¤§ä¸ˆå¤«ã ã¨æ€ã†ã‚“ã ã€‚ä¾‹ãˆã°ã€ä¸€éƒ¨ã®ç”°ã‚“ã¼ã§ã¾ãšè©¦ã—ã¦ã¿ã¦ã€åŠ¹æœã‚’è‡ªåˆ†ã®ç›®ã§ç¢ºã‹ã‚ã¦ã‹ã‚‰åºƒã’ã‚‹ã£ã¦ã„ã†æ–¹æ³•ã‚‚ã‚ã‚‹ã‚ˆã€‚ä¸€ç·’ã«ç›¸è«‡ã—ãªãŒã‚‰é€²ã‚ã¦ã„ã“ã†ã­ã€‚ä½•ã‹å…·ä½“çš„ãªè³ªå•ãŒã‚ã£ãŸã‚‰ã€é æ…®ãªãèã„ã¦ãã‚Œã‚ˆã€‚"
    
def format_prompt(user_message, history=None):
    conversation = ""
    if history:
        for user_msg, assistant_msg in history:
            if assistant_msg:
                conversation += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_msg}\nã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {assistant_msg}\n\n"
    
    full_message = conversation + f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_message}\nã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: "
    
    prompt = f"""<s>[INST] <<SYS>>
{SYSTEM_PROMPT}
<</SYS>>

{full_message} [/INST]"""
    return prompt

def generate_response(message, history):
    prompt = format_prompt(message, history)
    
    headers = {}
    if HF_API_TOKEN:
        headers["Authorization"] = f"Bearer {HF_API_TOKEN}"
    
    models_to_try = [HF_API_URL] + BACKUP_MODELS
    
    for model_url in models_to_try:
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_new_tokens": 512,
                "temperature": 0.7,
                "top_p": 0.9,
                "do_sample": True,
                "return_full_text": False,
            },
            "options": {
                "wait_for_model": True
            }
        }
        
        try:
            response = requests.post(model_url, headers=headers, json=payload, timeout=120)
            
            if response.status_code == 200:
                result = response.json()
                
                if isinstance(result, list) and len(result) > 0:
                    generated_text = result[0].get("generated_text", "")
                    generated_text = generated_text.strip()
                    if "[/INST]" in generated_text:
                        generated_text = generated_text.split("[/INST]")[-1].strip()
                    if "<s>" in generated_text:
                        generated_text = generated_text.split("<s>")[-1].strip()
                    return generated_text
                elif isinstance(result, dict) and "generated_text" in result:
                    generated_text = result["generated_text"].strip()
                    if "[/INST]" in generated_text:
                        generated_text = generated_text.split("[/INST]")[-1].strip()
                    return generated_text
                else:
                    continue
            
            elif response.status_code == 503:
                error_info = response.json() if response.content else {}
                estimated_time = error_info.get("estimated_time", 30)
                if model_url == models_to_try[0]:
                    return f"ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­ã§ã™ã€‚ç´„{estimated_time}ç§’ãŠå¾…ã¡ãã ã•ã„ã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
                else:
                    continue
            
            elif response.status_code in [410, 404]:
                continue
            
            elif response.status_code == 401:
                if not HF_API_TOKEN:
                    continue
                else:
                    continue
            
            else:
                print(f"Model {model_url} returned status {response.status_code}")
                continue
                
        except requests.exceptions.Timeout:
            continue
        except requests.exceptions.RequestException:
            continue
        except Exception:
            continue
    
    return generate_fallback_response(message)

def create_interface():
    with gr.Blocks(title="è¾²æ¥­ç›¸è«‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸŒ¾ è¾²æ¥­ç›¸è«‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ
        
        è¾²å®¶ã•ã‚“ã®è³ªå•ã‚„æ‡¸å¿µã«å¯¾ã—ã¦ã€è¦ªã—ã¿ã‚„ã™ãåˆ†ã‹ã‚Šã‚„ã™ã„å›ç­”ã‚’ã—ã¾ã™ã€‚
        è¾²æ¥­ã«é–¢ã™ã‚‹è³ªå•ã‚’æ°—è»½ã«ã©ã†ãï¼
        
        **æ³¨æ„**: ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯Hugging Face Inference APIã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
        """)
        
        chatbot = gr.Chatbot(
            label="ãƒãƒ£ãƒƒãƒˆ",
            height=500,
            show_copy_button=True
        )
        
        with gr.Row():
            msg = gr.Textbox(
                label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
                placeholder="è¾²æ¥­ã«é–¢ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
                scale=4,
                lines=2
            )
            submit_btn = gr.Button("é€ä¿¡", variant="primary", scale=1)
        
        with gr.Row():
            clear_btn = gr.Button("ä¼šè©±ã‚’ã‚¯ãƒªã‚¢", variant="secondary")
        
        gr.Markdown("### ğŸ’¡ è³ªå•ä¾‹")
        examples = gr.Examples(
            examples=[
                "ä¸­å¹²æœŸã‚’å»¶ã°ã™ã¨ç±³ãŒãƒ‘ã‚µãƒ‘ã‚µã«ãªã‚‹ã£ã¦èã„ãŸã‚“ã ã‘ã©ã€ãã‚“ãªãƒªã‚¹ã‚¯ã¯å–ã‚ŠãŸããªã„ã‚“ã ã‚ˆã€‚",
                "åé‡ãŒæ¸›ã£ãŸã‚‰ã©ã†ã™ã‚‹ã‚“ã ï¼Ÿå®¶æ—ã‚’é¤Šã£ã¦ã„ã‹ãªãã‚ƒãªã‚‰ãªã„ã‚“ã ã‚ˆã€‚",
                "æ°´ã®ç®¡ç†ãŒé›£ã—ããªã‚‹ã‚“ã˜ã‚ƒãªã„ã‹ï¼Ÿä»Šã§ã‚‚å¤§å¤‰ãªã®ã«ã€‚",
                "é«˜é½¢ã§ä½“åŠ›ã«è‡ªä¿¡ãŒãªã„ã‚“ã ã€‚æ–°ã—ã„ã“ã¨ã‚’è¦šãˆã‚‰ã‚Œã‚‹ã‹ãªã€‚",
            ],
            inputs=msg,
            label="ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„"
        )
        
        def user(user_message, history):
            return "", history + [[user_message, None]]
        
        def bot(history):
            if not history or not history[-1][0]:
                return history
            
            user_message = history[-1][0]
            response = generate_response(user_message, history[:-1])
            history[-1][1] = response
            return history
        
        msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(
            bot, chatbot, chatbot
        )
        submit_btn.click(user, [msg, chatbot], [msg, chatbot], queue=False).then(
            bot, chatbot, chatbot
        )
        clear_btn.click(lambda: None, None, chatbot, queue=False)
    
    return demo

if __name__ == "__main__":
    demo = create_interface()
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)

