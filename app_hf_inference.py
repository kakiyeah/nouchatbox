"""
Hugging Face Inference APIã‚’ä½¿ç”¨ã™ã‚‹è»½é‡ç‰ˆ
ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã›ãšã€Hugging Faceã®Inference APIã‚’ä½¿ç”¨ã—ã¾ã™
"""
import gradio as gr
import os
import requests

# Hugging Face Inference APIã®è¨­å®š
HF_API_URL = os.getenv("HF_API_URL", "https://api-inference.huggingface.co/models/elyza/ELYZA-japanese-Llama-2-7b-instruct")
HF_API_TOKEN = os.getenv("HF_API_TOKEN", "")

# ä¼˜åŒ–çš„System Prompt
SYSTEM_PROMPT = """ã‚ãªãŸã¯è¾²æ¥­æ¨é€²äº‹æ¥­è€…ã§ã™ã€‚è¾²å®¶ã•ã‚“ã®è³ªå•ã‚„æ‡¸å¿µã«å¯¾ã—ã¦ã€å…±æ„Ÿçš„ã§å…·ä½“çš„ãªå›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚

å›ç­”ã®ã‚¹ã‚¿ã‚¤ãƒ«ï¼š
- è¦ªã—ã¿ã‚„ã™ã„å£èªä½“ã‚’ä½¿ã†ï¼ˆã€ŒãŠã˜ã•ã‚“ã€ã€Œä¿ºã€ã€Œã ã‚ˆã­ã€ãªã©ï¼‰
- è¾²å®¶ã•ã‚“ã®æ°—æŒã¡ã«å…±æ„Ÿã™ã‚‹ï¼ˆã€Œãã†ã ã‚ˆã­ã€ã€Œå¿ƒé…ã ã‚ˆã­ã€ã€Œåˆ†ã‹ã‚‹åˆ†ã‹ã‚‹ã€ãªã©ï¼‰
- å…·ä½“çš„ãªä¾‹ã‚„å®Ÿéš›ã®çµŒé¨“ã‚’æŒ™ã’ã‚‹ï¼ˆã€Œå»å¹´å‚åŠ ã—ãŸâ—‹â—‹ã•ã‚“ã€ã€Œå®Ÿéš›ã«ã‚„ã£ã¦ã¿ã‚‹ã¨ã€ãªã©ï¼‰
- æŠ€è¡“çš„ãªå°‚é–€ç”¨èªã‚„çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã¯é¿ã‘ã‚‹
- æŸ”è»Ÿãªè§£æ±ºç­–ã‚’ææ¡ˆã™ã‚‹
- æ—¥å¸¸çš„ãªè¨€è‘‰ã‚„æ¯”å–©ã‚’ä½¿ã†
- è¾²å®¶ã•ã‚“ã‚’å°Šé‡ã—ã€å¼·åˆ¶ã—ãªã„å§¿å‹¢ã‚’ç¤ºã™
- å®Ÿè·µçš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„èª¬æ˜ã‚’ã™ã‚‹

ä»¥ä¸‹ã®ã‚ˆã†ãªè¡¨ç¾ã‚’é¿ã‘ã‚‹ï¼š
- ã€Œçµ±è¨ˆçš„ã«è¦‹ã¦ã€ã€Œãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚Œã°ã€ã€Œç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ãã€ãªã©ã®å°‚é–€çš„è¡¨ç¾
- ã€Œæ¨å¥¨ã„ãŸã—ã¾ã™ã€ã€Œå¿…è¦ã¨ãªã‚Šã¾ã™ã€ãªã©ã®ç¡¬ã„æ•¬èª
- æ•°å€¤ã‚„ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’å¤šç”¨ã™ã‚‹èª¬æ˜

ä»£ã‚ã‚Šã«ã€ä»¥ä¸‹ã®ã‚ˆã†ãªè¡¨ç¾ã‚’ä½¿ã†ï¼š
- ã€Œå®Ÿéš›ã«ã‚„ã£ã¦ã¿ã‚‹ã¨ã€ã€Œå»å¹´ã®ãƒ‡ãƒ¼ã‚¿è¦‹ã¦ã‚‚ã€
- ã€Œä¸€ç·’ã«ã‚„ã£ã¦ã¿ã‚ˆã†ã‚ˆã€ã€Œç›¸è«‡ã—ã‚ˆã†ã­ã€
- ã€Œå¤§ä¸ˆå¤«ã ã‚ˆã€ã€Œå®‰å¿ƒã—ã¦ã€ãªã©ã®å®‰å¿ƒæ„Ÿã‚’ä¸ãˆã‚‹è¨€è‘‰"""

def format_prompt(user_message, history=None):
    """æ ¼å¼åŒ–æç¤ºè¯"""
    conversation = ""
    if history:
        for user_msg, assistant_msg in history:
            if assistant_msg:
                conversation += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_msg}\nã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: {assistant_msg}\n\n"
    
    full_message = conversation + f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_message}\nã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: "
    
    prompt = f"""<s>[INST] <<SYS>>
{SYSTEM_PROMPT}
<</SYS>>

{full_message} [/INST]"""
    return prompt

def generate_response(message, history):
    """ä½¿ç”¨Hugging Face Inference APIç”Ÿæˆå›ç­”"""
    prompt = format_prompt(message, history)
    
    headers = {}
    if HF_API_TOKEN:
        headers["Authorization"] = f"Bearer {HF_API_TOKEN}"
    
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 512,
            "temperature": 0.7,
            "top_p": 0.9,
            "do_sample": True,
            "return_full_text": False,
        },
        "options": {
            "wait_for_model": True
        }
    }
    
    try:
        response = requests.post(HF_API_URL, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        
        if isinstance(result, list) and len(result) > 0:
            generated_text = result[0].get("generated_text", "")
            # æ¸…ç†å›ç­”
            generated_text = generated_text.strip()
            # ç§»é™¤å¯èƒ½çš„é‡å¤æç¤ºè¯
            if "[/INST]" in generated_text:
                generated_text = generated_text.split("[/INST]")[-1].strip()
            return generated_text
        else:
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
    
    except requests.exceptions.RequestException as e:
        return f"APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}ã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

# åˆ›å»ºGradioç•Œé¢
def create_interface():
    with gr.Blocks(title="è¾²æ¥­ç›¸è«‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸŒ¾ è¾²æ¥­ç›¸è«‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ
        
        è¾²å®¶ã•ã‚“ã®è³ªå•ã‚„æ‡¸å¿µã«å¯¾ã—ã¦ã€è¦ªã—ã¿ã‚„ã™ãåˆ†ã‹ã‚Šã‚„ã™ã„å›ç­”ã‚’ã—ã¾ã™ã€‚
        è¾²æ¥­ã«é–¢ã™ã‚‹è³ªå•ã‚’æ°—è»½ã«ã©ã†ãï¼
        
        **æ³¨æ„**: ã“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯Hugging Face Inference APIã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
        """)
        
        chatbot = gr.Chatbot(
            label="ãƒãƒ£ãƒƒãƒˆ",
            height=500,
            show_copy_button=True
        )
        
        with gr.Row():
            msg = gr.Textbox(
                label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
                placeholder="è¾²æ¥­ã«é–¢ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
                scale=4,
                lines=2
            )
            submit_btn = gr.Button("é€ä¿¡", variant="primary", scale=1)
        
        with gr.Row():
            clear_btn = gr.Button("ä¼šè©±ã‚’ã‚¯ãƒªã‚¢", variant="secondary")
        
        # ç¤ºä¾‹é—®é¢˜
        gr.Markdown("### ğŸ’¡ è³ªå•ä¾‹")
        examples = gr.Examples(
            examples=[
                "ä¸­å¹²æœŸã‚’å»¶ã°ã™ã¨ç±³ãŒãƒ‘ã‚µãƒ‘ã‚µã«ãªã‚‹ã£ã¦èã„ãŸã‚“ã ã‘ã©ã€ãã‚“ãªãƒªã‚¹ã‚¯ã¯å–ã‚ŠãŸããªã„ã‚“ã ã‚ˆã€‚",
                "åé‡ãŒæ¸›ã£ãŸã‚‰ã©ã†ã™ã‚‹ã‚“ã ï¼Ÿå®¶æ—ã‚’é¤Šã£ã¦ã„ã‹ãªãã‚ƒãªã‚‰ãªã„ã‚“ã ã‚ˆã€‚",
                "æ°´ã®ç®¡ç†ãŒé›£ã—ããªã‚‹ã‚“ã˜ã‚ƒãªã„ã‹ï¼Ÿä»Šã§ã‚‚å¤§å¤‰ãªã®ã«ã€‚",
                "é«˜é½¢ã§ä½“åŠ›ã«è‡ªä¿¡ãŒãªã„ã‚“ã ã€‚æ–°ã—ã„ã“ã¨ã‚’è¦šãˆã‚‰ã‚Œã‚‹ã‹ãªã€‚",
            ],
            inputs=msg,
            label="ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„"
        )
        
        # äº‹ä»¶å¤„ç†
        def user(user_message, history):
            return "", history + [[user_message, None]]
        
        def bot(history):
            if not history or not history[-1][0]:
                return history
            
            user_message = history[-1][0]
            response = generate_response(user_message, history[:-1])
            history[-1][1] = response
            return history
        
        msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(
            bot, chatbot, chatbot
        )
        submit_btn.click(user, [msg, chatbot], [msg, chatbot], queue=False).then(
            bot, chatbot, chatbot
        )
        clear_btn.click(lambda: None, None, chatbot, queue=False)
    
    return demo

if __name__ == "__main__":
    demo = create_interface()
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)

